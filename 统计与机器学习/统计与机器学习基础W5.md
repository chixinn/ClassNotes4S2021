## 统计与机器学习基础

## 中心化

$x_1,x_2,...,x_n$

求均值$\bar{x}$

中心化即为$x_i^*=x_i-\bar{x}$

**x和y同时都需要中心化**

是对数据中心化前or后跑模型。

![截屏2021-03-30 08.07.34](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.07.34.png)

$\beta=(\beta_{intercept},\beta_{slope}')$

> 中心化后，intercept的估计永远是0，slope不变,slope是与x有关的部分

## 补充--分块矩阵求逆

![截屏2021-03-30 08.10.22](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.10.22.png)

这里假设A是可逆的，不可逆用行变换把D翻上去

把数据看成理论模型的重复抽样。

将X矩阵，记成$X=(1_n,X_0),X_0=(x_1,x_2,..,x_p)$，这里$x_1,x_2,...,x_p$是列向量

## 原始最小二乘估计

![截屏2021-03-30 08.19.22](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.19.22.png)![截屏2021-03-30 08.19.22](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.19.22.png)$1_n^T1=n$

把第二行的2*2的矩阵看成分块矩阵求逆。

把$(D-CA^{-1}B)^{-1}$看成$A_0$

## 对x和y都做中心化，求最小二乘估计

$X_c$标示X_centered

$X_0$标示X_original

用中心化后的数据建模一样可以得到OLSE，即除了符号，其它基本上没有什么差异

![截屏2021-03-30 08.30.10](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.30.10.png)

## 将中心化也看成数据投影？

$\bar{y}=\frac{1}{n}\sum y_i=\frac{1}{n}1_n^T\vec{y}$,这里$\frac{1}{n}$可以写成$(1_n^T1_n)'$

所以$\bar{y}=(1_n^T1_n)'1_n\vec{y}$的投影。

所以$\vec{y^*}=\begin{pmatrix}y_1-\bar{y}\\y_2-\bar{y}\end{pmatrix}$

![截屏2021-03-30 08.35.45](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.35.45.png)

这里，$1_n(1_n'1_n)^{-1}1_n'$是一个投影矩阵

![截屏2021-03-30 08.37.18](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.37.18.png)

把每一个$X_i$按列排，写起来。

> 将中心化类比于一个投影关系

## 去中心化后的参数估计

![截屏2021-03-30 08.40.00](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.40.00.png)

$X_C=(I_n-H_{1n})X_0$

$1_n'(I_n-H_{1n})$永远是0向量，前面有证明，这里$1_n'X_c$还是0向量。

这说明了中心化，对数据从事了什么事，去掉某垂直空间?

## 证明$A_c=A_0$

![截屏2021-03-30 08.44.12](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.44.12.png)

这里把$n^{-1}$进行恢复，作为数放进$1_n1_n'$中间，构造出$H_{1n}$的形式。

### 证明$\beta_{slope}$不变

![截屏2021-03-30 08.47.30](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.47.30.png)

![截屏2021-03-30 08.47.06](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.47.18.png)

这里$H_{1n}$是对称幂等的。$H=X(X'X)^{-1}X'$也是对称幂等的。

![截屏2021-03-30 08.51.59](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.51.59.png)

对于标准化，复杂在L矩阵。

> 数据变换对回归是否有关系，标准化有关系，中心化无关系

## 检验模型是否靠谱

检验->分布假设：

![截屏2021-03-30 08.54.31](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.54.31.png)

## F检验

x前的系数是否都不为0，都为0无法刻画。

F检验刻画误差信息量与模型信息量之间的权衡。

总偏差：没有建模型，$y_i-\bar{y}$

建立模型以后，模型给出了每一个观测的拟合值$\hat{y_i}-\bar{y}$

残差：$y_i-\hat{y_i}$

![截屏2021-03-30 08.58.44](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 08.58.44.png)

## 多元知识补充

![截屏2021-03-30 09.00.19](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 09.00.19.png)

这个定理里需要去验证C矩阵是否是对称幂等矩阵，且rank(C)是否为r

非中心化的参数$\delta$，$\mu'$是零向量，$\delta$退化为0.

![截屏2021-03-30 09.02.08](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 09.02.08.png)

把SSR/SSE写成正态分布二次型的结构。

 幂等矩阵：平方向化成一次。

**对称幂等矩阵的rank等于trace.**

![截屏2021-03-30 09.04.55](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 09.04.55.png)

这里，y是一个多元正态，

$SSE=y'(I-H)y$

$SSE/\sigma^2$是卡方()

$X'(I-H)=X'-X'H=X'X-X'X(X'X)^{-1}X'=0$是

![截屏2021-03-30 09.11.08](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 09.11.08.png)



![截屏2021-03-30 09.17.16](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 09.17.16.png)

Y'和y都看成正态分布，中间仍是看成一个常数矩阵，这里A是$(x_i-\bar{x})(x_i-\bar{x})$。因为x'(I-H)是0，所以一整行都是0.

![截屏2021-03-30 09.20.03](/Users/chixinning/Library/Application Support/typora-user-images/截屏2021-03-30 09.30.18.png)

