# 统计与机器学习基础W4:一元线性回归(2)

一元线性回归是用统计去拟合一个y最有可能的值。

对于每一个x都有一个确定的y的分布$p(y|x)$。所以我们要找的"y"，其实是$E[Y|x]=f(x)=\int yp(y|x)dy$

线性回归是针对回归系数要求线性。

$y=f(x)+\epsilon$

## 三大基本假设

1. $x$被假定为一般变量，非随机变量，是严格控制或精确测量的。
2. $E[\epsilon]=0,Var(\epsilon)=\sigma^2,$就算期望不为0也会被吸收。
3. $\epsilon$~i.i,d $N(0,\epsilon^2)$

## 一元线性回归的基本形式

$y_i=\beta_0+\beta_1x_i+\epsilon_i$

$y_i$～$N(\beta_0+\beta_1x_i,\sigma^2)$

## 估计系数

### LSE & MLE

$\hat{\beta_1}=\frac{l_{xy}}{l_{xx}}$ 本质上就是$y_1,y_2,...,y_n$的线性组合

$\hat{\beta_0}=\bar{y}-\beta_1\bar{x}$

## 回归系数检验方法

知道多种检验方法可以让我们使用很少的已知数据得到我们想要的结果，防止因为数据量的缺失而使计算无法进行。

$\beta_1=0$ v.s.	$\beta_1\neq0$

### t检验

求$\hat{\beta_1}$的分布，$\beta_1$~$N(0,\frac{\sigma^2}{l_{xx}})$

残差:

$e_i=y_i-\beta_0-\beta_1x_i$也服从正态分布

$\hat{\sigma^2}=\frac{1}{n-2}\sum e_i^2$；残差平方和$SSE$

不加证明的说明残差服从自由度$n-2$的卡方分布。

所以有正太和卡方可以构造t分布

$\frac{\hat{\beta_1}}{\hat{\sigma^2}/l_{xx}}$～$t(n-2)$

### F检验

$sst=sse+ssr$

$ss_T=l_{yy}=\sum(y_i-\bar{y})^2$

$SSE=(y_i-\hat{y_i})$残差平方和

$SSR=(\hat{y_i}-\bar{y})^2$叫回归平方和

![[公式]](https://www.zhihu.com/equation?tex=SSR) 服从自由度为1的卡方分布，而 ![[公式]](https://www.zhihu.com/equation?tex=SSE) 服从自由度为 ![[公式]](https://www.zhihu.com/equation?tex=n-2) 的卡方分布（上面已经见过它了）。

$\frac{ssR/1}{SSE/(n-2)}$~$F(1,n-2)$

> 矩阵在回归分析中的应用

### 相关系数

$r=\frac{l_{xy}}{\sqrt{l_{xx}l_{yy}}}$

$r^2=\frac{l_{xy}^2}{l_{xx}l_{yy}}$,$l_{yy}=SST$

$ssR=\sum(\hat{y_i}-\bar{y})^2=\hat{\beta_1}^2l_{xx}$

$ssr/sst=lxy^2 lxx/lxx^2/lyy=(lxy)^2/lxxlyy=r^2$

统计学上$ssr/sst$为决定系数等于$r^2$

